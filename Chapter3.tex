\ifdefined\included
\else
\documentclass[a4paper,11pt,twoside]{StyleThese}
\include{formatAndDefs}
\sloppy
\begin{document}
\setcounter{chapter}{2} %% Numéro du chapitre précédent ;)
\dominitoc
\faketableofcontents
\fi

\chapter{Evaluating communication needs at task planning level}
\minitoc
\printnomenclature

\section{Introduction and Example}
In the previous chapter, we showed interactions are more efficient and satisfactory if the robot consider the plan of the human in its own path of action. Not only it allows at least to ensure that the task is feasible for both agents (provided the models are correct enough) but also to perform coordination smoothers or other communication actions.

In this chapter, we alleviate from the inherent complexity of geometrical navigation planning to further study at symbolic level the planning of communication actions in plans involving multiple agents. We will especially focus on one type of explicit communication, being verbally designating an object, a problem called referring expression generation.

To entrench the problem and illustrate this chapter contents, let us take the situation depicted in Figure~\ref{fig:chap3illustrate} \improvement{Add figure}.  

First, we review the literature concerning referring expression generation and communication actions in task planning. Then we present a novel approach for referring expression generation, which runs on ontologies and is both efficient and suitable for human robot interaction scenarios. We then show how such a communication planner can be included in task planning allowing for precise estimation of communication feasibility and cost at task planning level. Finally, an extension of the referring expression generation algorithm is presented using past actions and tasks to refer to objects.

\section{Related Work}
We claim that estimating the content of some communication at task planning level is needed to generate useful plans. Indeed, some communication actions are known to be necessary already while elaborating a plan, but might not be feasible.
In this section we will firstly review how a robot can autonomously verbally designate an object to an hearer. This problem is called the \textbf{referring expression generation} (REG) problem.
Then, we will review several task planning approaches allowing to account for communication actions.

\subsection{Referring Expression Generation}
As defined by Reiter and Dale, Referring Expression Generation (REG) "\textit{is concerned with how we produce a description of an entity that enables the hearer to identify that entity in a given context} \cite{reiter1997building}. An intuition about what a well constructed referring expression (RE) is, is given by the Grice's maxims \cite{grice1975logic}. These maxims aim at defining principles for smooth cooperative activities (including verbal communication). They fall into four categories:
\begin{itemize}
\item \textit{Quantity}: The communication should be as informative as required but not more.
\item \textit{Quality}: The communication should be as true as possible. The sender should not communicate information that they consider false or unsure.
\item \textit{Relation}: The communication should be relevant in the current context. This is especially important when performing a collaborative task, where the world state is constantly changing and the relevance of a communication can quickly change.
\item \textit{Manner}: The communication should be unambiguous and brief.
\end{itemize}

The REG problem is actually composed of two parts: the content determination --- aiming at deciding which attributes (and relations) to use --- and the linguistic realization --- refining the attributes of the content into verbalizable/writable words \cite{krahmer2012computational}. In this thesis, we will only consider the content determination, as we assume that the linguistic realization will not have any impact on the plan once the content of the RE has been decided.

To our knowledge the first REG formulation and algorithm was coined by Dale and used a depth-first search over a knowledge base being a key-value tree representing attribute of objects \cite{dale1989cooking}. However, this approach lead to over specified referring expressions, containing redundant information and thus violating the maxim of quantity. This defect was corrected in a subsequent work with the \textit{Full Brevity} algorithm \cite{dale1992generating}, always generating the shortest referring expression, but at the cost of an exhaustive search. Besides, to be as relevant as possible, the attribute of the referred object to be included in the RE should be chosen carefully. Indeed, not all the attributes are equally understandable by the hearer, the color or the shape for example will often be quicker to understand than spatial relation. The Incremental Algorithm is the first approach tackling this issue \cite{dale1995computational}. By taking as input a preference list of ordered attributes, it is able to generate the smallest RE while prioritizing the attribute used.

However, all the presented approaches are running on dedicated key-value knowledge bases representing only the attribute of the entities and are thus unable to use relations between them to generate REs. For example, an object having the same attributes (color, size, shape, ...) as another one will not have any RE generated by the previous approaches, even if one is in a blue box and the other in a green one. By introducing a new knowledge representation, being a labeled directed multi-graph linking entities and attributes, Krahmer \textit{et al.} were able to solve this issue. The graph is dedicated to the problem of REG and is called a \textit{REG graph}. Moreover, a cost can be set on each edge of the graph to represent the complexity of the hearer to understand this relation. By exploring this graph through a branch and bound approach, the Graph-Based Algorithm \cite{krahmer2003graph} is able to generate the smallest and less costly RE for a given entity. This algorithm has then been refined to integrate types of entities in the exploration \cite{krahmer2012computational}, to be more computationnally efficent \cite{li2017automatically} or to over specify the RE \cite{viethen2013graphs}.

Other approaches also include learning for generating REs. Yamakata \textit{et al.} use a beliefs network based method to disambiguate entities based on multiple attributes \cite{yamakata2004belief}. Besides, they state that their algorithm runs on the hearer estimated belief network, we think that it is an important feature to generate relevant REs. However, they indicate that a belief network should be trained for each attribute, which can be really impractical in a real world robotic application.

Every approach presented until then are relying on REG dedicated knowledge bases or data structures. Such structures can be cumbersome to maintain in a dynamic world where relations between entities can change along the task. Moreover, in complete robotic architecture knowledge bases managing relations already exists, but are not dedicated to REG. The DIST-PIA method tries to mitigate this issue by having a domain-independent Incremental Algorithm querying dedicated knowledge base consultants to elaborate the RE \cite{williams2017referring}. This approach has been successfully integrated in a complete robotic architecture \cite{williams2019dempster}. Another work having been integrated into a robotic architecture is made by Ros \textit{et al.} \cite{ros2010one}. The knowledge base used is an ontology, which is more and more used in robotics to store symbolic knowledge. However, it does not support using the relations to generate REs (it only relies on the attributes of the entities). It has been integrated in a robotic architecture allowing the robot to guess the object the human is thinking of in a dynamic environment \cite{lemaignan2012grounding}.

To the best of our knowledge, none of these approaches have been used to determine the feasability and the cost of a referring communication action at task planning level.



\subsection{Task Planning with Communication Actions}

Recently, more and more research is dedicated to human robot verbal communication planning, mainly to answer the \textit{what} and the \textit{when} to communicate \cite{mavridis2015review}. The vast majority of works treats these questions during execution. Indeed, they assume a given plan (multi-agents or not) and insert verbal communication actions when needed.
\textit{Chaski} is a plan execution system allowing to perform collaborative activity with a human \cite{shah2011improved}. The system is able to generate verbal communication when starting or finishing a task allowing agents to coordinate their actions and to update their plans.
With their \textit{inverse semantic} algorithm, Tellex \textit{et al.} provide the robot with a capability to ask a nearby human for help when it fails \cite{tellex2014asking}. Indeed, when following a plan, if the robot detects an unfeasible action, it can plan which human action would help it in the plan and is able, using REG \textit{inter alia}, to verbally demand them to act. 
Sebastiani \textit{et al.} are able, by merging multiple multi-agent HATP plans, to generate conditional plans which then can be verbally negotiated (by asking the human about task allocation) during the execution with the human \cite{sebastiani2017dealing}. 
Devin and Alami proposed a supervision component which is able, when given a multi-agent plan elaborated by HATP, to estimate the beliefs of the human partner \cite{devin2016implemented}. Then, they monitor divergences between the robot and the human's beliefs. If a divergence is detected as not allowing the human to perform their next actions of the plan, a verbal communication aligning the needed belief is done by the robot. 

However, in all the previous work, the need and the content of communication actions are resolved only when executing the plan. This is in some case not enough and more recent works focus on resolving communication needs already at task planning level.
Roncone \textit{et al.} propose a task planner where domains are easily written and visualized thanks to an high-level task tree representation \cite{roncone2017transparent}. This domain is then changed into a POMDP which can be solved to obtain a policy. They define three types of verbal communication: (1) \textit{command} is a robot instruction to the human, which can be accepted or declined; (2) \textit{ask} allows the robot to question the human about the progress of their task; and (3) \textit{inform} makes the robot speaks about its next action intent. These three types of action are coded in the POMDP and may be included in the policy depending on the situation and their cost.
A similar approach has been realized by Unhelkar \textit{et al.} where they add one type of communication: \textit{answer} allowing the robot to answer a human querying about its next intent \cite{unhelkar2020decision}. These verbal communication actions are then integrated into a POMDP. This POMDP is elaborated thanks to a provided task model represented as an multi-agent MDP, a robot communication model (including communication cost model) and a human action selection model represented with an agent Markov model. This human model can be refined throughout the interaction. The POMDP is then solved to generate a robot policy.
It is interesting to note that in the presented works, the communication costs are only based on the time of execution (the \textit{when}) --- to ensure multiple communications are not too close in time --- but not on the content of said communication (the \textit{what}, \textit{e.g.} the length of the communication, the complexity of understanding it). Moreover, by not considering the content of the communication at planning time (communication actions are considered as template with arguments determined at execution time) they do not ensure that it will be feasible when executing. They mitigate this issue by only considering communication about the plan and actions, and not about belief alignment or object referring.
Finally, it appears clear in the presented works that planning for communication can only be done if the robot plans for both agents.


\improvement{Add a conductor example, the ones with cubes and areas maybe ?}
\section{Ontology based Referring Expression Generation for Human Robot Interaction}
To estimate the feasibility and the cost of communication action during task planning, we need to be able to quickly resolve the content of a communication. Since considering every type of communication would be intractable we focus on a special type of verbal communication: referring expressions.
In this section we present an efficient algorithm that is able to generate referring expression for human-robot interaction based on ontologies. We first introduce the concept of ontology and argue about its use in human-robot interaction scenarios. Then we propose a list a features needed for REG in human-robot interaction. Next, we formally define the problem of ontology-based REG for HRI, and present an efficient algorithm to solve it. Finally, we show the results of this approach both in term of found solutions and time complexity.

This part has been done in close collaboration with Guillaume Sarthou.

\subsection{Using ontologies for human robot interaction}
An ontology is a data representation used in many domains. In robotics it is more and more used as a knowledge base. It allows to represent multiple concepts inheriting from one another and entities as instantiation of these concepts. Moreover, the entities can be linked through properties representing relations. Reasoners can use this structure to deduce and complete the ontology. Recently, ontologies are even standardized for robotic application such as the IEEE-SA P1872.2 Standard for Autonomous Robotics Ontology.

Formally, as coined by ... \cite{ontology_def}, an knowledge base ontology is defined by the tuple $K = \langle \abox, \tbox, \rbox \rangle$. 
The \textit{TBox} $\tbox$ contains the concepts, called \textit{classes} representing the possible types of entities known by the agent. More specifically, it is a finite directed acyclic graph (DAG) $\tbox = \langle T, H \rangle$ with $T$ the set of classes/types and $H$ the directed edges representing the inheritance/inclusion links between them. For simplicity purposes we will refer to them as \textit{isA} links. In an ontology representing the example depicted in Figure~\ref{fig:chapter3_example}, we may have: $\{Cube, Table, Object, Agent, Pickable, Robot, Human\} \subset T$ and $\{(Cube, Pickable), (Pickable, Object), (Table, Object), (Robot, Agent), (Human, Agent)\} \subset H$ (\textit{i.e.} $(Cube, isA, Pickable), (Pickable, isA, Object), (Table, isA, Object), (Robot, isA, Agent), (Human, isA, Agent)$). 
The RBox $\rbox = \langle P, Incl, Inv \rangle$ contains the properties, their inheritances and inverses known by the agent. $P$ is the set of properties, $Incl$ the finite DAG representing inheritances/inclusions between the properties and $Inv = \{(p_i, p_j) \in P^2\}$ representing the inverse properties. In an ontology representing the example depicted in Figure~\ref{fig:chapter3_example} the RBox may include: $\{isIn, hasIn, isOn, hasOn, geometricProperty\} \subset P$, $\{(isIn, geometricProperty), (hasIn, geometricProperty), (isOn, geometricProperty), (hasOn, geometricProperty)\} \subset Incl$ and $\{(isIn, hasIn), (hasIn, isIn), (isOn, hasOn), (hasOn, isOn)\} \subset Inv$. Note that to fully match the definition of ... \cite{ontology_ref} it would require to declare the disjunctive, transitive, reflexive and chain relations in $\rbox$ and the disjunctive classes in $\tbox$. As they will reasoned upon in this thesis, we chose to omit them.
Finally, the ABox $\abox = \langle A, C_0, R \rangle$ contains the entities, their types and relations. $A$ is the set of entities. $C_0 = \{(a, t)|a \in A, t \in T\}$ contains the direct types of each entities (an entity must have at least one direct type, but can have multiple ones). Finally $R = \{(s, p, o)|(s, o) \in A^2, p \in P\}$ is the set of relations between entities. For example, in an ontology representing the example of Figure~\ref{fig:chapter3_example} we would have in the ABox: $\{cube_23, cube_12, table_1, human_3, pr2_robot\} \subset A$ along with $\{(cube_23, Cube), (cube_12, Cube), (table_1, Table), (human_3, Human), (pr2_robot, Robot)\} \subset C_0$ and $(cube_23, isOn, table_1) \in R$.
By using the hierarchy of types we also define $C$ representing the graph of direct and inherited types of entities. $C$ is constructed by adding all the types that can be reached from a direct type of an entity by following a path in $H$. For example $(cube_23, Cube) \in C_0 \implies (cube_23, Cube) \in C \land (cube_23, Pickable) \in C \land (cube_23, Object) \in C$ if we reuse the example $H$ presented before.
We define the "isA" property for simplicity purpose. The "isA" property allows to represent hierarchy of types and entities types (as defined in $C$) while only representing triplet, as typical relation (\textit{e.g.} $(cube_23, isA, Cube)$, $(cube_23, isA, Pickable)$, $(cube_23, isA, Object)$. This definition is only intended to help with the notation.

In all the following work we will consider the TBox and RBox as static. They will be defined before any experiment and will not be modified at runtime. They can be considered as the semantic knowledge of the robot. The ABox on the other hand, will contain both predefined entities and relations but also sensed entities and computed facts. It will contain usual symbolic facts, computed by the situation assessment, found in the knowledge bases of typical robotics architecture. However, thanks to their typing and the hierarchy of both types and properties deduction and reasoning can be done on them.

In this thesis we will not present the different reasoners of the ontology, but rather assume that the ontologies used are all been preprocessed and are consistent (\textit{e.g.} if a relation is in $R$, all the inverse properties of this relation have been added to $R$).


% One ontology per agent
Finally, we want to be able to estimate and reason on the human beliefs. To do so, we will use one knowledge base (\textit{i.e.} ontology) per agent considered by the robot in addition to its own. To follow the notation of Chakraborti \cite{chakraborti2018human} presented earlier in this thesis, we will note $K^R = \langle \abox^R, \tbox^R, \rbox^R \rangle$ the knowledge base of the robot and $K^H_r = \langle \abox^H_r, \tbox^H_r, \rbox^H_r \rangle$ the robot estimated knowledge base of the human it is interacting with. In practice, we will have $\tbox^R = \tbox^H_r$ and $\rbox^R = \rbox^H_r$, and only have differences in the ABoxes.

\subsection{REG feature for communication action estimation during task planning}
We saw previously that REG is an important and interesting problem for human-robot interaction scenarios. However, as its application will be on an environment perceived in real-time, along a collaborative task and to a specific human, additional constraints have to been considered.

First, we want to be able to \textbf{use the relations between entities} to refer to one. 
Then, we want the algorithm to \textbf{run on existing knowledge bases}. Many presented approaches rely on a dedicated knowledge representation. Such representation can be cumbersome to maintain during an interaction in an evolving environment. 
Moreover, we claim that the ontologies used already contain the knowledge needed to perform the REG. We also want to support the \textbf{preference ordering} per agent. Indeed, some relations are understood better and quicker than other, and this preference can change depending on the agent we are interacting with. 
In addition, we want the algorithm to consider the verbalization through \textbf{the use of types}. All the approaches presented before only focus on the content determination of the REG and consider that the linguistic realization (the verbalization) will be perfect. They consider that all the content can be verbalized (it exists a word for every bit of the content and the content can be verbalized unambiguously). We state that the type is the minimal information needed to refer to an entity (\textit{e.g.} the \textit{cube\_23} cannot be verbalized directly as "cube 23", only its type can be verbalized as "the cube").
Likewise, we can imagine that in large robotic ontologies, every type or relation cannot be verbalized (\textit{e.g.} we do not want the robot to say \textit{pickable} type or the \textit{geometricProperty}). Thus, our algorithm should be able to \textbf{select only verbalizable types properties}.
Finally, in an interaction, it is clear for the hearer that some entities will not be referred, and should not be taken into account as distractors by the algorithm (in the example depicted in Figure~\ref{fig:example_chapter3}, it should be clear to the human that, unless specified otherwise, if the robot ask about a cube, it is one on the table and not one in another room). Equally, some relations will be implied (\textit{e.g.} if the robot asks the human to \textit{give} it a cube, it is implied that the cube is not reachable by the robot and reachable by the human). Thus, the algorithm must \textbf{use the context of the ongoing task}.

\subsection{Ontology based REG problem definition}


\subsection{Efficient REG algorithm presentation}
% Sparql, here or in the ontology presentations

\subsection{Results}


\section{Planning Communication Actions Using Referring Expression Generation}



\section{Using Past Actions in Referring Expression Generation}

\section{Conclusion}

\ifdefined\included
\else
\bibliographystyle{acm}
\bibliography{These}
\end{document}
\fi
