\chapter{HATP/EHDA Domains for the Coffee Bringer Examples}
\label{annex:codedomains}

The \acrfull{hatpehda} is presented in Chapter~\ref{chapter:doublehtn} along with illustrative examples allowing to present its features. We propose to report here the interesting parts of the domains in Python, as they were used for running the examples.

\section{Plan for Robot Unknown Human Knowledge}
\label{annex:domainmugs}
In this example, the robot has been asked by a human to bring her a coffee. However, multiple mugs are on the table in front of the robot and the human, and the robot does not know which one belongs to the human.

\begin{lstlisting}[language=Python]
import hatpehda
from copy import deepcopy
from hatpehda import gui
from hatpehda.reg import REGHandler

regHandler = None

### Helpers

def same_last_tasks(plan, n, task=None):
    """
    Given a partial 'plan', returns True if the 'n' last tasks of the partial plan are the same (and optionnaly equal to 'task')
    """
    if len(plan) < n:
        return False
    last_tasks = [plan[-i].name for i in range(1, n + 1)]
    if task is not None and last_tasks[0] != task:
        return False
    return last_tasks.count(last_tasks[0]) == len(last_tasks)

### Primitive tasks

def robot_pick_mug(agents, self_state, self_name, mug):
    """
    Checks if the 'mug' is reachable by the agent (robot) and if the agent does not carry anything.
    Then updates the beliefs of all the agents in the same room as the robot as for the robot having picked the 'mug'
    """
    if self_name in self_state.isReachableBy[mug] and self_state.isHolding[self_name] == []:
        robot_room = self_state.isInRoom[self_name][0]
        for agent_name in self_state.agentsInRoom[robot_room]:
            a = agents[agent_name]
            a.state.isReachableBy[mug] = []
            a.state.isHolding[self_name] = [mug]
            a.state.isHeldBy[mug] = [self_name]
        return agents
    return False


def robot_ask_mug_to_take(agents, self_state, self_name, human):
    """
    Asks the 'human' which one is their mug by adding to their agenda that they will answer the question.
    Note that we could have checked if the communication was feasible
    """
    hatpehda.add_tasks(human, [("human_answer_mug_a", self_name)], agents)
    return agents

def robot_drop_mug(agents, self_state, self_name):
    """
    Checks if the robot is holding something.
    If so, update all the agents in the room beliefs with the fact that the robot as dropped what they thought it was holding.
    """
    if self_state.isHolding[self_name] != []:
        robot_room = self_state.isInRoom[self_name][0]
        for agent_name in self_state.agentsInRoom[robot_room]:
            a = agents[agent_name]
            mug = a.state.isHolding[self_name]
            if mug != []:
                mug, = mug
                a.state.isReachableBy[mug] = [self_name]
                a.state.isHolding[self_name] = []
                a.state.isHeldBy[mug] = []
        return agents
    return False

def robot_go_to_coffee_machine(agents, self_state, self_name):
    """
    This action has no effect nor preconditions. It only represents the robot leaving the room (for the example)
    """
    return agents

def human_verbally_answer_right_mug(agents, self_state, self_name, robot, mug):
    """

    """
    # We make a REG request to check if we estimate that the human will be able to refer to their mug
    ctx = [("?0", "isAbove", "table_1")]
    symbols = {"?0": mug}
    # This function copy the ontology of 'self_name' (human), update it with beliefs from 'self_state' and runs
    # a REG request with 'ctx' and 'symbols' as context with the target entity 'mug'
    reg = regHandler.get_re(self_name, self_state, ctx, symbols, mug)
    if not reg.success:
        return False

    human_room = self_state.isInRoom[self_name][0]
    for agent_name in self_state.agentsInRoom[human_room]:
        a = agents[agent_name]
        a.state.isOwnedBy[mug] = self_name
    return agents

def human_complain_mug(agents, self_state, self_name, robot):
    """
    This primitive task models the human complaining about the mug that the robot is 'holding' not being theirs. 
    We update all the agents in the room beliefs, with the mug held by the 'robot' not being the one 'self_name' (human)
    """
    human_room = self_state.isInRoom[self_name][0]
    for agent_name in self_state.agentsInRoom[human_room]:
        a = agents[agent_name]
        mug = a.state.isHolding[robot]
        if mug is not None and mug != []:
            mug, = mug
            a.state.isNotOwnedBy[mug] = self_name
    return agents
    
# As we don't know the agents name in advance, we store the operators here, until a plan request
ctrl_operators = [robot_pick_mug, robot_drop_mug, robot_ask_mug_to_take, robot_go_to_coffee_machine]
unctrl_operators = [human_verbally_answer_right_mug, human_complain_mug]
    
    
### Abstract tasks decompositions

def robot_ask_take_mug(agents, self_state, self_name, human):
    if same_last_tasks(agents[human].plan, 3, "WAIT"):
        return False
    for mug, h in self_state.isOwnedBy.items():
        if h == human:
            return [("robot_pick_mug", mug)]
    for mug in self_state.individuals["Mug"]:
        if mug not in self_state.isNotOwnedBy or human not in self_state.isNotOwnedBy[mug]:
            return [("robot_ask_mug_to_take", human), ("robot_get_right_mug", human)]
    return False

# This decorator informs the planner that this decomposition return several disjunctive sequences of tasks
# (typically for multiple possible parameter instantiation
@hatpehda.multi_decomposition
def robot_take_one_random_mug(agents, self_state, self_name, human):
    if same_last_tasks(agents[human].plan, 3, "WAIT"):
        return False
    for mug, h in self_state.isOwnedBy.items():
        if h == human:
            return False
    task_list = []
    for mug in self_state.individuals["Mug"]:
        if mug not in self_state.isNotOwnedBy or human not in self_state.isNotOwnedBy[mug]:
            task_list.append([("robot_pick_mug", mug)])
    if task_list == []:
        return False
    return task_list


def human_agree_mug_taken(agents, self_state, self_name, robot, mug):
    return []

def human_disagree_mug_taken(agents, self_state, self_name, robot, mug):
    return [("human_complain_mug", robot)]

@hatpehda.multi_decomposition
def human_answer_mug(agents, self_state, self_name, robot):
    for mug, h in self_state.isOwnedBy.items():
        if h == self_name:
            return [[("human_verbally_answer_right_mug", robot, mug)]]
    task_list = []
    for mug in self_state.individuals["Mug"]:
        if mug not in self_state.isNotOwnedBy or self_name not in self_state.isNotOwnedBy[mug]:
            task_list.append([("human_verbally_answer_right_mug", robot, mug)])
    if task_list == []:
        return False
    return task_list


# We don't know the agents name beforehand so we store them here, until we can add the proper agents
# Syntax: ('abstract_task_name', decompo1, decompo2, ...)
ctrl_methods = [("robot_get_right_mug", robot_take_one_random_mug, robot_ask_take_mug)]
unctrl_methods = [("human_answer_mug_a", human_answer_mug), ("human_check_mug_taken", human_agree_mug_taken, human_disagree_mug_taken)]
    

# Triggers
def human_check_mug(agents, self_state, self_name):
    if agents["robot"].plan[-1].name == "robot_pick_mug":
        mug = self_state.isHolding["robot"][0]
        if mug in self_state.isNotOwnedBy and self_state.isNotOwnedBy[mug] == self_name:
            return False
        for action in agents[self_name].plan:
            if action.name == "human_verbally_answer_right_mug" and action.parameters[1] == mug:
                return False
        return [("human_check_mug_taken", "robot", mug)]
    return False

def robot_check_wrong_mug(agents, self_state, self_name):
    if self_state.isHolding[self_name] is not None and self_state.isHolding[self_name] != []:
        heldMug = self_state.isHolding[self_name][0]
        if heldMug in self_state.isNotOwnedBy and "human" == self_state.isNotOwnedBy[heldMug]:
            return [("robot_drop_mug", ), ("robot_get_right_mug", "human")]
    return False
    
    
if __name__ == "__main__":
    regHandler = REGHandler()

    n_mug = 2

    state = hatpehda.State("robot_init")
    state.types = {"Agent": ["isHolding"], "Mug": ["isHeldBy", "isReachableBy"]}
    state.individuals = {'Mug': ["mug_{}".format(i) for i in range(n_mug)]}
    state.isHeldBy = {m: [] for m in state.individuals["Mug"]}
    state.isHolding = {"human": [], "robot": []}
    state.isOwnedBy = {}
    state.isNotOwnedBy = {}
    state.isReachableBy = {m: ["human", "robot"] for m in state.individuals["Mug"]}
    state.agentsInRoom = {"office": ["human", "robot"]}
    state.isInRoom = {"human": ["office"], "robot": ["office"]}

    hatpehda.declare_operators("robot", *ctrl_operators)
    for me in ctrl_methods:
        hatpehda.declare_methods("robot", *me)
    hatpehda.declare_triggers("robot", *ctrl_triggers)
    hatpehda.declare_operators("human", *unctrl_operators)
    for me in unctrl_methods:
        hatpehda.declare_methods("human", *me)
    hatpehda.declare_triggers("human", *unctrl_triggers)

    hatpehda.set_state("robot", state)
    hatpehda.add_tasks("robot", [("robot_get_right_mug", "human"), ("robot_go_to_coffee_machine", )])  # Agenda initialization

    human_state = deepcopy(state)  # No beliefs divergence (detected) in this example
    human_state.__name__ = "human_init"
    hatpehda.set_state("human", human_state)


    sols = []
    fails = []
    hatpehda.seek_plan_robot(hatpehda.agents, "robot", sols, "human", fails)

    cost, cplan = select_plan(sols)
    gui.show_plan(cplan, "robot", "human")
\end{lstlisting}

\section{Balance Difficult Communications, Decomposition Cost and Task Attribution}
\label{annex:domaincoffee}
In this example, the robot has to prepare coffee. It detects a human nearby, who does not appear to be performing a task. To prepare coffee, coffee needs to be retrieved from one of the two cupboards (one is closer than the other) and put in the machine; and water must be poured in the machine. We want the robot to balance between doing all on its own or asking the human for help. Moreover, we estimate that the human thinks there are some coffee in the nearest cupboard, while the robot knows there is not. Thus, we also want the robot to balance between aligning these beliefs or letting the human potentially make the mistake.

\begin{lstlisting}[language=Python]
import hatpehda
from copy import deepcopy
from hatpehda import gui

### Helpers

def agent_plan_contains(plan, task_name):
    for p in plan:
        if p.name == task_name:
            return True
    return False

### Primitive tasks

def robot_get_water(agents, self_state, self_name):
    if self_state.isHolding[self_name] is not None and self_state.isHolding[self_name] != []:
        return False
    for ag in agents.values():
       ag.state.isHolding[self_name] = ["water"]
    return agents

def robot_pour_water_in_machine(agents, self_state, self_name):
    if self_state.isHolding[self_name] is None or self_state.isHolding[self_name] == []:
        return False
    for ag in agents.values():
        ag.state.contains["coffee_machine"].append(ag.state.isHolding[self_name][0])
        ag.state.isHolding[self_name] = []
    return agents

def robot_pick_coffee(agents, self_state, self_name, closet):
    if self_state.isHolding[self_name] is not None and self_state.isHolding[self_name] != []:
        return False
    if self_state.contains[closet] is None or self_state.contains[closet] == []:
        return False
    for ag in agents.values():
       ag.state.isHolding[self_name] = ["coffee"]
    return agents

def robot_put_coffee_in_machine(agents, self_state, self_name):
    if self_state.isHolding[self_name] is None or self_state.isHolding[self_name] == []:
        return False
    for ag in agents.values():
        ag.state.contains["coffee_machine"].append(ag.state.isHolding[self_name][0])
        ag.state.isHolding[self_name] = []
    return agents

def robot_ask_human_for_help(agents, self_state, self_name, human):
    hatpehda.add_tasks(human, [("human_help_make_coffee", self_name)], agents)
    return agents

def robot_serve_coffee(agents, _, __):
    return agents

def robot_update_human_inventory(agents, self_state, self_name, human, closet):
    agents[human].state.contains[closet] = self_state.contains[closet]
    return agents

def human_get_water(agents, self_state, self_name):
    if self_state.isHolding[self_name] is not None and self_state.isHolding[self_name] != []:
        return False
    for ag in agents.values():
        ag.state.isHolding[self_name] = ["water"]
    return agents

def human_pour_water_in_machine(agents, self_state, self_name):
    if self_state.isHolding[self_name] is None or self_state.isHolding[self_name] == []:
        return False
    for ag in agents.values():
        ag.state.contains["coffee_machine"].append(ag.state.isHolding[self_name][0])
        ag.state.isHolding[self_name] = []
    return agents

def human_try_pick_coffee(agents, self_state, self_name, closet):
    if self_state.isHolding[self_name] is not None and self_state.isHolding[self_name] != []:
        return False
    if agents["robot"].state.contains[closet] is None or agents["robot"].state.contains[closet] == []:
        self_state.contains[closet] = agents["robot"].state.contains[closet]
        return agents
    for ag in agents.values():
        ag.state.isHolding[self_name] = ["coffee"]
    return agents

def human_put_coffee_in_machine(agents, self_state, self_name):
    if self_state.isHolding[self_name] is None or self_state.isHolding[self_name] == []:
        return False
    for ag in agents.values():
        ag.state.contains["coffee_machine"].append(ag.state.isHolding[self_name][0])
        ag.state.isHolding[self_name] = []
    return agents


# As we don't know the agents name in advance, we store the operators here, until a ros plan call
ctrl_operators = [robot_get_water, robot_pour_water_in_machine, robot_pick_coffee, robot_put_coffee_in_machine,
                  robot_update_human_inventory, robot_ask_human_for_help, robot_serve_coffee]
unctrl_operators = [human_get_water, human_pour_water_in_machine, human_try_pick_coffee, human_put_coffee_in_machine]

### Abstract Tasks

@hatpehda.multi_decomposition
def robot_make_coffee_alone(agents, self_state, self_name):
    return [[("robot_get_water",), ('robot_pour_water_in_machine',), ("robot_get_coffee", ), ("robot_put_coffee_in_machine", )],
            [("robot_get_coffee",), ("robot_put_coffee_in_machine",), ("robot_get_water",), ('robot_pour_water_in_machine',)]]

def robot_collaborate_make_coffee_no_comm(agents, self_state, self_name):
    return [("robot_ask_human_for_help", "human"), ("robot_help_make_coffee", "human")]

@hatpehda.multi_decomposition
def robot_collaborate_make_coffee_with_belief_update(agents, self_state, self_name):
    tasks = []
    for cupboard in self_state.individuals["Cupboard"]:
        if agents['human'].state.contains[cupboard] != self_state.contains[cupboard]:
            tasks.append([("robot_update_human_inventory", "human", cupboard), ("robot_ask_human_for_help", "human"), ("robot_help_make_coffee", "human")])
    if tasks == []:
        return False # Another decomposition handles it
    return tasks

@hatpehda.multi_decomposition
def robot_help_make_coffee(agents, self_state, self_name, human):
    if "water" in self_state.isHolding[human] and "coffee" not in self_state.contains["coffee_machine"]:
        return [[("robot_get_coffee",), ("robot_put_coffee_in_machine",)]]
    if agent_plan_contains(agents[human].plan, "human_try_pick_coffee") and "water" not in self_state.contains["coffee_machine"]:
        return [[("robot_get_water",), ("robot_pour_water_in_machine",)]]
    tasks = []
    if "coffee" not in self_state.contains["coffee_machine"]:
        tasks.append([("robot_get_coffee",), ("robot_put_coffee_in_machine",), ("robot_help_make_coffee", human)])
    if "water" not in self_state.contains["coffee_machine"]:
        tasks.append([("robot_get_water",), ("robot_pour_water_in_machine",), ("robot_help_make_coffee", human)])
    return tasks

def robot_get_coffee(agents, self_state, self_name):
    if "coffee" in self_state.isHolding[self_name]:
        return []
    min_cupboard = None
    min_dist = 999999.0
    for cupboard in self_state.individuals["Cupboard"]:
        if "coffee" in self_state.contains[cupboard] and self_state.distances[cupboard][0] < min_dist:
            min_dist = self_state.distances[cupboard][0]
            min_cupboard = cupboard
    if min_cupboard is None:
        return False
    return [("robot_pick_coffee", min_cupboard), ("robot_get_coffee", )]

@hatpehda.multi_decomposition
def human_help_make_coffee(agents, self_state, self_name, robot):
    if "water" in self_state.isHolding[robot] and "coffee" not in self_state.contains["coffee_machine"]:
        return [[("human_get_coffee",), ("human_put_coffee_in_machine",)]]
    if "coffee" in self_state.isHolding[robot] and "water" not in self_state.contains["coffee_machine"]:
        return [[("human_get_water",), ("human_pour_water_in_machine",)]]
    tasks = []
    if "coffee" not in self_state.contains["coffee_machine"]:
        tasks.append( [("human_get_coffee",), ("human_put_coffee_in_machine",), ("human_help_make_coffee", robot)])
    if "water" not in self_state.contains["coffee_machine"]:
        tasks.append([("human_get_water",), ("human_pour_water_in_machine",), ("human_help_make_coffee", robot)])
    return tasks


def human_get_coffee(agents, self_state, self_name):
    if "coffee" in self_state.isHolding[self_name]:
        return []
    min_cupboard = None
    min_dist = 999999.0
    for cupboard in self_state.individuals["Cupboard"]:
        if "coffee" in self_state.contains[cupboard] and self_state.distances[cupboard][0] < min_dist:
            min_dist = self_state.distances[cupboard][0]
            min_cupboard = cupboard
    if min_cupboard is None:
        return False
    return [("human_try_pick_coffee", min_cupboard), ("human_get_coffee",)]


# We don't know the agents name in advance so we store them here, until we can add the proper agents
ctrl_methods = [("robot_make_coffee", robot_make_coffee_alone, robot_collaborate_make_coffee_no_comm, robot_collaborate_make_coffee_with_belief_update),
                ("robot_help_make_coffee", robot_help_make_coffee),
                ("robot_get_coffee", robot_get_coffee)]
unctrl_methods = [("human_help_make_coffee", human_help_make_coffee), ("human_get_coffee", human_get_coffee)]


if __name__ == "__main__":
    state = hatpehda.State("robot_init")
    state.types = {"Agent": ["isHolding"]}
    state.individuals = { "Cupboard": ["kitchen_cupboard", "pantry_cupboard"]}
    state.isHolding = {"human": [], "robot": []}
    state.contains = {"coffee_machine": [], "kitchen_cupboard": [], "pantry_cupboard": ["coffee"]}
    state.distances = {"kitchen_cupboard": [2.0], "pantry_cupboard": [4.0]}

    hatpehda.declare_operators("robot", *ctrl_operators)
    for me in ctrl_methods:
        hatpehda.declare_methods("robot", *me)
    hatpehda.declare_operators("human", *unctrl_operators)
    for me in unctrl_methods:
        hatpehda.declare_methods("human", *me)
    hatpehda.set_state("robot", state)
    hatpehda.add_tasks("robot", [("robot_make_coffee", ), ("robot_serve_coffee", )])  # Agenda initialization

    human_state = deepcopy(state)
    human_state.__name__ = "human_init"
    human_state.contains = {"coffee_machine": [], "kitchen_cupboard": ["coffee"], "pantry_cupboard": ["coffee"]}
    # Belief divergence: while the robot knows that kitchen_cupboard does not contain anything, the human thinks it is
    # containing coffee
    hatpehda.set_state("human", human_state)


    sols = []
    fails = []
    hatpehda.seek_plan_robot(hatpehda.agents, "robot", sols, "human", fails)

    cost, cplan = select_policies(sols)
    gui.show_plan(cplan, "robot", "human", with_abstract=True)
\end{lstlisting}

