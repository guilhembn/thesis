\ifdefined\included
\else
\documentclass[a4paper,11pt,twoside]{StyleThese}
\include{formatAndDefs}
\sloppy
\begin{document}
\fi


\chapter*{Introduction}
\addstarredchapter{Introduction} %Sinon cela n'apparait pas dans la table des matiÃ¨res
Humans and machines are now collaborating for a long time. On one hand, what started as simple tools quickly gained in complexity and are now robots able to autonomously act on the world with little to no human supervision. On the other hand, humans are more and more dependent on these machines, both for everyday and more specific tasks.
However, both acting on the environment and having some autonomy can lead to incident and injuries if a robotic system is not well made or if a human has not received a specific formation. This is why currently in the industry we see a strong physical separation between human and robots, or some annoying light and sound systems when robots share human environments. Indeed, while the Fitts's HABA MABA \cite{fitts_human_1951} distinction is getting blurrier, some major interaction challenges have not been tackled yet.

In this thesis we propose to explore a way to bring the human and robot closer in order to make them perform tasks in shared environments in a safer and more usable manner than existing systems. To do so, we claim that robots must be able to make their decision based not only on their own perception of the environment but also on their estimation of the beliefs of their human partner. Moreover, the robot must be able to plan taking into account that the other agent will also plan, act and react to the actions of the robot.

\section*{Human Robot Interaction}
%%% AI less error posible vs. mimicry the human
%%% HRI: mimicry the human, trying cognitive architecture on robot to check models, or less error possible-> in two ways, mimicrying the human (that is the thing we know working the best currently), or trying other stuff... We try other stuff
The literature on human robot interaction regroups a wide range of approaches and visions. As in artificial intelligence, a distinction can be made between systems trying to act like humans and systems trying to act rationally. Moreover, some approaches also tries to implement human cognitive models on robot to validate them \cite{act-R}.

In this manuscript, the approach chosen is to make a system acting rationally. Besides, we define the human robot interaction as Goodrich and Schultz as being \textit{the field of study dedicated to understanding, designing, and evaluating robotic systems for use by or with humans}. Thus, the goal is to make a robotic system allowing to, when used by or with humans, to perform a task in the most effective, efficient and satisfactory way. To put it otherwise, we aim at making the most usable (as defined in ISO 9241-11) robotic system.

It worth mentioning that some work focusing on the goal described above still mimicry some human behaviors. Indeed, the best working interaction example we currently have access to is humans collaborating with human. In this thesis, even if the human behavior may be taken as an inspiration, the argument that the robot should act in a certain way because the human does so will not be used.



\section*{Motion and Task Planning}
We consider both humans and robots as agents. An agent is an entity able to modify its environment (and its own state) by performing actions. Now if an agent is given an objective (a specific environment state) and has an estimation of what its actions will change in this environment, it can try to figure out a succession of actions leading to that objective. This process is called planning.



 

\ifdefined\included
\else
\bibliographystyle{acm}
\bibliography{These}
\end{document}
\fi